# Explainable-AI-is-Responsible-AI
A survey of transparency in AI approaches


Modern AI design choices make AI decision calculations indecipherable to both developers and end-users. This lack of transparency has the potential to create an array of problems, ranging from errors and a lack of trust to existential risks for humanity, such as the stop-button problem where human-desired safeguards stand in direct opposition to agent goals. Current research compares multiple AI designs for transparency to single out more responsible, trustworthy, and safe approaches.

This document is draft of research paper as the work is still in progress.
